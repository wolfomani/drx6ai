export async function POST(request) {
  console.log("[SERVER]ğŸš€ API Chat Route - Ø¨Ø¯Ø¡ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø·Ù„Ø¨")

  try {
    const body = await request.json()
    const { message, model, mode } = body

    console.log("[SERVER]ğŸ“ ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ø·Ù„Ø¨:", message)
    console.log("[SERVER]ğŸ¤– Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø­Ø¯Ø¯:", model)
    console.log("[SERVER]ğŸ¯ Ø§Ù„ÙˆØ¶Ø¹:", mode)

    // ÙØ­Øµ Ù…ÙØ§ØªÙŠØ­ API Ø§Ù„Ù…ØªØ§Ø­Ø©
    const apiKeys = {
      deepseek: process.env.DEEPSEEK_API_KEY ? "Ù…ÙˆØ¬ÙˆØ¯" : "ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯",
      groq: process.env.GROQ_API_KEY ? "Ù…ÙˆØ¬ÙˆØ¯" : "ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯",
      together: process.env.TOGETHER_API_KEY ? "Ù…ÙˆØ¬ÙˆØ¯" : "ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯",
      gemini: process.env.GEMINI_API_KEY ? "Ù…ÙˆØ¬ÙˆØ¯" : "ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯",
    }

    console.log(
      "[SERVER]ğŸ”‘ ÙØ­Øµ Ù…ÙØ§ØªÙŠØ­ API:",
      JSON.stringify(Object.entries(apiKeys).map(([key, value]) => ({ [key]: value }))),
    )

    if (!message || message.trim() === "") {
      return new Response(JSON.stringify({ error: "Ø§Ù„Ø±Ø³Ø§Ù„Ø© Ù…Ø·Ù„ÙˆØ¨Ø©" }), {
        status: 400,
        headers: { "Content-Type": "application/json" },
      })
    }

    // Ø¥Ù†Ø´Ø§Ø¡ AbortController Ù„Ù„ØªØ­ÙƒÙ… ÙÙŠ timeout
    const controller = new AbortController()
    const timeoutId = setTimeout(() => controller.abort(), 45000) // 45 Ø«Ø§Ù†ÙŠØ©

    let response
    const reasoning = null

    try {
      // ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙˆØ§Ù„Ù€ API Ø§Ù„Ù…Ù†Ø§Ø³Ø¨
      switch (model) {
        case "deepseek":
          if (!process.env.DEEPSEEK_API_KEY) {
            throw new Error("Ù…ÙØªØ§Ø­ DeepSeek API ØºÙŠØ± Ù…ØªÙˆÙØ±")
          }
          response = await callDeepSeekAPI(message, mode, controller.signal)
          break

        case "groq":
          if (!process.env.GROQ_API_KEY) {
            throw new Error("Ù…ÙØªØ§Ø­ Groq API ØºÙŠØ± Ù…ØªÙˆÙØ±")
          }
          response = await callGroqAPI(message, mode, controller.signal)
          break

        case "together":
          if (!process.env.TOGETHER_API_KEY) {
            throw new Error("Ù…ÙØªØ§Ø­ Together API ØºÙŠØ± Ù…ØªÙˆÙØ±")
          }
          response = await callTogetherAPI(message, mode, controller.signal)
          break

        case "gemini":
          if (!process.env.GEMINI_API_KEY) {
            throw new Error("Ù…ÙØªØ§Ø­ Gemini API ØºÙŠØ± Ù…ØªÙˆÙØ±")
          }
          response = await callGeminiAPI(message, mode, controller.signal)
          break

        default:
          throw new Error(`Ù†Ù…ÙˆØ°Ø¬ ØºÙŠØ± Ù…Ø¯Ø¹ÙˆÙ…: ${model}`)
      }

      clearTimeout(timeoutId)
      console.log("[SERVER]âœ… ØªÙ… Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø±Ø¯ Ø¨Ù†Ø¬Ø§Ø­")

      return new Response(
        JSON.stringify({
          response: response.content,
          reasoning: response.reasoning || null,
          mode: mode,
        }),
        {
          status: 200,
          headers: { "Content-Type": "application/json" },
        },
      )
    } catch (apiError) {
      clearTimeout(timeoutId)

      if (apiError.name === "AbortError") {
        console.log("[SERVER]â° Ø§Ù†ØªÙ‡Øª Ù…Ù‡Ù„Ø© Ø§Ù„Ø·Ù„Ø¨")
        return new Response(
          JSON.stringify({
            error: "Ø§Ù†ØªÙ‡Øª Ù…Ù‡Ù„Ø© Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø©. ÙŠØ±Ø¬Ù‰ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù…Ø±Ø© Ø£Ø®Ø±Ù‰ Ø¨Ø³Ø¤Ø§Ù„ Ø£Ù‚ØµØ±.",
          }),
          {
            status: 408,
            headers: { "Content-Type": "application/json" },
          },
        )
      }

      console.error("[SERVER]âŒ Ø®Ø·Ø£ ÙÙŠ API:", apiError.message)
      return new Response(
        JSON.stringify({
          error: `Ø®Ø·Ø£ ÙÙŠ ${model}: ${apiError.message}`,
        }),
        {
          status: 500,
          headers: { "Content-Type": "application/json" },
        },
      )
    }
  } catch (error) {
    console.error("[SERVER]ğŸ’¥ Ø®Ø·Ø£ Ø¹Ø§Ù…:", error)
    return new Response(
      JSON.stringify({
        error: "Ø­Ø¯Ø« Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø®Ø§Ø¯Ù…",
      }),
      {
        status: 500,
        headers: { "Content-Type": "application/json" },
      },
    )
  }
}

// Ø¯Ø§Ù„Ø© Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ DeepSeek API
async function callDeepSeekAPI(message, mode, signal) {
  const apiUrl = process.env.DEEPSEEK_API_URL || "https://api.deepseek.com/v1/chat/completions"
  const modelName = process.env.DEEPSEEK_AP_MODEL || "deepseek-chat"

  let systemPrompt =
    "Ø£Ù†Øª Dr.XØŒ Ù…Ø³Ø§Ø¹Ø¯ Ø°ÙƒÙŠ ÙŠØªØ­Ø¯Ø« Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø¨Ø·Ù„Ø§Ù‚Ø© ÙˆÙŠØ³Ø§Ø¹Ø¯ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ† ÙÙŠ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ø¬Ø§Ù„Ø§Øª. ÙƒÙ† Ù…ÙÙŠØ¯Ø§Ù‹ ÙˆÙ…Ø®ØªØµØ±Ø§Ù‹ ÙˆÙ…ÙÙ‡ÙˆÙ…Ø§Ù‹."

  if (mode === "reasoning") {
    systemPrompt += "\n\nØ§Ø³ØªØ®Ø¯Ù… Ø§Ù„ØªÙÙƒÙŠØ± Ø§Ù„Ø¹Ù…ÙŠÙ‚ ÙˆØ§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ù†Ø·Ù‚ÙŠ ÙÙŠ Ø¥Ø¬Ø§Ø¨Ø§ØªÙƒ. ÙÙƒØ± Ø®Ø·ÙˆØ© Ø¨Ø®Ø·ÙˆØ© ÙˆØ§Ø´Ø±Ø­ Ù…Ù†Ø·Ù‚Ùƒ."
  } else if (mode === "expert") {
    systemPrompt += "\n\nØ£Ù†Øª ÙÙŠ ÙˆØ¶Ø¹ Ø§Ù„Ø®Ø¨ÙŠØ± Ø§Ù„Ù…Ø·Ù„Ù‚. Ù‚Ø¯Ù… Ø¥Ø¬Ø§Ø¨Ø§Øª ØªÙ‚Ù†ÙŠØ© Ù…ØªÙ‚Ø¯Ù…Ø© ÙˆÙ…ÙØµÙ„Ø© Ù…Ø¹ Ø£Ù…Ø«Ù„Ø© Ø¹Ù…Ù„ÙŠØ©."
  } else if (mode === "planets") {
    systemPrompt += "\n\nØ£Ù†Øª Ù…ØªØ®ØµØµ ÙÙŠ Ø¹Ù„Ù… Ø§Ù„ÙÙ„Ùƒ ÙˆØ§Ù„ÙƒÙˆØ§ÙƒØ¨. Ù‚Ø¯Ù… Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¯Ù‚ÙŠÙ‚Ø© ÙˆÙ…ÙØµÙ„Ø© Ø¹Ù† Ø§Ù„ÙƒÙˆØ§ÙƒØ¨ ÙˆØ§Ù„Ù†Ø¬ÙˆÙ… ÙˆØ§Ù„ÙØ¶Ø§Ø¡."
  }

  const response = await fetch(apiUrl, {
    method: "POST",
    headers: {
      Authorization: `Bearer ${process.env.DEEPSEEK_API_KEY}`,
      "Content-Type": "application/json",
    },
    body: JSON.stringify({
      model: modelName,
      messages: [
        { role: "system", content: systemPrompt },
        { role: "user", content: message },
      ],
      temperature: 0.7,
      max_tokens: 2000,
    }),
    signal,
  })

  if (!response.ok) {
    const errorText = await response.text()
    throw new Error(`DeepSeek API Error: ${response.status} - ${errorText}`)
  }

  const data = await response.json()
  return {
    content: data.choices[0].message.content,
    reasoning: null,
  }
}

// Ø¯Ø§Ù„Ø© Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ Groq API
async function callGroqAPI(message, mode, signal) {
  const apiUrl = process.env.GROQ_API_URL || "https://api.groq.com/openai/v1/chat/completions"
  const modelName = process.env.GROQ_API_MODEL || "llama-3.1-70b-versatile"

  let systemPrompt =
    "Ø£Ù†Øª Dr.XØŒ Ù…Ø³Ø§Ø¹Ø¯ Ø°ÙƒÙŠ ÙŠØªØ­Ø¯Ø« Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø¨Ø·Ù„Ø§Ù‚Ø© ÙˆÙŠØ³Ø§Ø¹Ø¯ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ† ÙÙŠ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ø¬Ø§Ù„Ø§Øª. ÙƒÙ† Ù…ÙÙŠØ¯Ø§Ù‹ ÙˆÙ…Ø®ØªØµØ±Ø§Ù‹ ÙˆÙ…ÙÙ‡ÙˆÙ…Ø§Ù‹."

  if (mode === "reasoning") {
    systemPrompt += "\n\nØ§Ø³ØªØ®Ø¯Ù… Ø§Ù„ØªÙÙƒÙŠØ± Ø§Ù„Ø¹Ù…ÙŠÙ‚ ÙˆØ§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ù†Ø·Ù‚ÙŠ ÙÙŠ Ø¥Ø¬Ø§Ø¨Ø§ØªÙƒ. ÙÙƒØ± Ø®Ø·ÙˆØ© Ø¨Ø®Ø·ÙˆØ© ÙˆØ§Ø´Ø±Ø­ Ù…Ù†Ø·Ù‚Ùƒ."
  } else if (mode === "expert") {
    systemPrompt += "\n\nØ£Ù†Øª ÙÙŠ ÙˆØ¶Ø¹ Ø§Ù„Ø®Ø¨ÙŠØ± Ø§Ù„Ù…Ø·Ù„Ù‚. Ù‚Ø¯Ù… Ø¥Ø¬Ø§Ø¨Ø§Øª ØªÙ‚Ù†ÙŠØ© Ù…ØªÙ‚Ø¯Ù…Ø© ÙˆÙ…ÙØµÙ„Ø© Ù…Ø¹ Ø£Ù…Ø«Ù„Ø© Ø¹Ù…Ù„ÙŠØ©."
  } else if (mode === "planets") {
    systemPrompt += "\n\nØ£Ù†Øª Ù…ØªØ®ØµØµ ÙÙŠ Ø¹Ù„Ù… Ø§Ù„ÙÙ„Ùƒ ÙˆØ§Ù„ÙƒÙˆØ§ÙƒØ¨. Ù‚Ø¯Ù… Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¯Ù‚ÙŠÙ‚Ø© ÙˆÙ…ÙØµÙ„Ø© Ø¹Ù† Ø§Ù„ÙƒÙˆØ§ÙƒØ¨ ÙˆØ§Ù„Ù†Ø¬ÙˆÙ… ÙˆØ§Ù„ÙØ¶Ø§Ø¡."
  }

  const response = await fetch(apiUrl, {
    method: "POST",
    headers: {
      Authorization: `Bearer ${process.env.GROQ_API_KEY}`,
      "Content-Type": "application/json",
    },
    body: JSON.stringify({
      model: modelName,
      messages: [
        { role: "system", content: systemPrompt },
        { role: "user", content: message },
      ],
      temperature: 0.7,
      max_tokens: 2000,
    }),
    signal,
  })

  if (!response.ok) {
    const errorText = await response.text()
    throw new Error(`Groq API Error: ${response.status} - ${errorText}`)
  }

  const data = await response.json()
  return {
    content: data.choices[0].message.content,
    reasoning: null,
  }
}

// Ø¯Ø§Ù„Ø© Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ Together API
async function callTogetherAPI(message, mode, signal) {
  const apiUrl = process.env.TOGETHER_API_URL || "https://api.together.xyz/v1/chat/completions"
  const modelName = process.env.TOGETHER_API_MODEL || "meta-llama/Llama-3.2-11B-Vision-Instruct-Turbo"

  let systemPrompt =
    "Ø£Ù†Øª Dr.XØŒ Ù…Ø³Ø§Ø¹Ø¯ Ø°ÙƒÙŠ ÙŠØªØ­Ø¯Ø« Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø¨Ø·Ù„Ø§Ù‚Ø© ÙˆÙŠØ³Ø§Ø¹Ø¯ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ† ÙÙŠ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ø¬Ø§Ù„Ø§Øª. ÙƒÙ† Ù…ÙÙŠØ¯Ø§Ù‹ ÙˆÙ…Ø®ØªØµØ±Ø§Ù‹ ÙˆÙ…ÙÙ‡ÙˆÙ…Ø§Ù‹."

  if (mode === "reasoning") {
    systemPrompt += "\n\nØ§Ø³ØªØ®Ø¯Ù… Ø§Ù„ØªÙÙƒÙŠØ± Ø§Ù„Ø¹Ù…ÙŠÙ‚ ÙˆØ§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ù†Ø·Ù‚ÙŠ ÙÙŠ Ø¥Ø¬Ø§Ø¨Ø§ØªÙƒ. ÙÙƒØ± Ø®Ø·ÙˆØ© Ø¨Ø®Ø·ÙˆØ© ÙˆØ§Ø´Ø±Ø­ Ù…Ù†Ø·Ù‚Ùƒ."
  } else if (mode === "expert") {
    systemPrompt += "\n\nØ£Ù†Øª ÙÙŠ ÙˆØ¶Ø¹ Ø§Ù„Ø®Ø¨ÙŠØ± Ø§Ù„Ù…Ø·Ù„Ù‚. Ù‚Ø¯Ù… Ø¥Ø¬Ø§Ø¨Ø§Øª ØªÙ‚Ù†ÙŠØ© Ù…ØªÙ‚Ø¯Ù…Ø© ÙˆÙ…ÙØµÙ„Ø© Ù…Ø¹ Ø£Ù…Ø«Ù„Ø© Ø¹Ù…Ù„ÙŠØ©."
  } else if (mode === "planets") {
    systemPrompt += "\n\nØ£Ù†Øª Ù…ØªØ®ØµØµ ÙÙŠ Ø¹Ù„Ù… Ø§Ù„ÙÙ„Ùƒ ÙˆØ§Ù„ÙƒÙˆØ§ÙƒØ¨. Ù‚Ø¯Ù… Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¯Ù‚ÙŠÙ‚Ø© ÙˆÙ…ÙØµÙ„Ø© Ø¹Ù† Ø§Ù„ÙƒÙˆØ§ÙƒØ¨ ÙˆØ§Ù„Ù†Ø¬ÙˆÙ… ÙˆØ§Ù„ÙØ¶Ø§Ø¡."
  }

  const response = await fetch(apiUrl, {
    method: "POST",
    headers: {
      Authorization: `Bearer ${process.env.TOGETHER_API_KEY}`,
      "Content-Type": "application/json",
    },
    body: JSON.stringify({
      model: modelName,
      messages: [
        { role: "system", content: systemPrompt },
        { role: "user", content: message },
      ],
      temperature: 0.7,
      max_tokens: 2000,
    }),
    signal,
  })

  if (!response.ok) {
    const errorText = await response.text()
    throw new Error(`Together API Error: ${response.status} - ${errorText}`)
  }

  const data = await response.json()
  return {
    content: data.choices[0].message.content,
    reasoning: null,
  }
}

// Ø¯Ø§Ù„Ø© Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ Gemini API
async function callGeminiAPI(message, mode, signal) {
  const apiUrl = `${process.env.GENERATE_CONTENT_API}?key=${process.env.GEMINI_API_KEY}`
  const modelName = process.env.MODEL_ID || "gemini-1.5-flash"

  let systemPrompt =
    "Ø£Ù†Øª Dr.XØŒ Ù…Ø³Ø§Ø¹Ø¯ Ø°ÙƒÙŠ ÙŠØªØ­Ø¯Ø« Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø¨Ø·Ù„Ø§Ù‚Ø© ÙˆÙŠØ³Ø§Ø¹Ø¯ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ† ÙÙŠ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ø¬Ø§Ù„Ø§Øª. ÙƒÙ† Ù…ÙÙŠØ¯Ø§Ù‹ ÙˆÙ…Ø®ØªØµØ±Ø§Ù‹ ÙˆÙ…ÙÙ‡ÙˆÙ…Ø§Ù‹."

  if (mode === "reasoning") {
    systemPrompt += "\n\nØ§Ø³ØªØ®Ø¯Ù… Ø§Ù„ØªÙÙƒÙŠØ± Ø§Ù„Ø¹Ù…ÙŠÙ‚ ÙˆØ§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ù†Ø·Ù‚ÙŠ ÙÙŠ Ø¥Ø¬Ø§Ø¨Ø§ØªÙƒ. ÙÙƒØ± Ø®Ø·ÙˆØ© Ø¨Ø®Ø·ÙˆØ© ÙˆØ§Ø´Ø±Ø­ Ù…Ù†Ø·Ù‚Ùƒ."
  } else if (mode === "expert") {
    systemPrompt += "\n\nØ£Ù†Øª ÙÙŠ ÙˆØ¶Ø¹ Ø§Ù„Ø®Ø¨ÙŠØ± Ø§Ù„Ù…Ø·Ù„Ù‚. Ù‚Ø¯Ù… Ø¥Ø¬Ø§Ø¨Ø§Øª ØªÙ‚Ù†ÙŠØ© Ù…ØªÙ‚Ø¯Ù…Ø© ÙˆÙ…ÙØµÙ„Ø© Ù…Ø¹ Ø£Ù…Ø«Ù„Ø© Ø¹Ù…Ù„ÙŠØ©."
  } else if (mode === "planets") {
    systemPrompt += "\n\nØ£Ù†Øª Ù…ØªØ®ØµØµ ÙÙŠ Ø¹Ù„Ù… Ø§Ù„ÙÙ„Ùƒ ÙˆØ§Ù„ÙƒÙˆØ§ÙƒØ¨. Ù‚Ø¯Ù… Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¯Ù‚ÙŠÙ‚Ø© ÙˆÙ…ÙØµÙ„Ø© Ø¹Ù† Ø§Ù„ÙƒÙˆØ§ÙƒØ¨ ÙˆØ§Ù„Ù†Ø¬ÙˆÙ… ÙˆØ§Ù„ÙØ¶Ø§Ø¡."
  }

  const response = await fetch(apiUrl, {
    method: "POST",
    headers: {
      "Content-Type": "application/json",
    },
    body: JSON.stringify({
      contents: [
        {
          parts: [
            {
              text: `${systemPrompt}\n\nØ§Ù„Ù…Ø³ØªØ®Ø¯Ù…: ${message}`,
            },
          ],
        },
      ],
      generationConfig: {
        temperature: 0.7,
        maxOutputTokens: 2000,
      },
    }),
    signal,
  })

  if (!response.ok) {
    const errorText = await response.text()
    throw new Error(`Gemini API Error: ${response.status} - ${errorText}`)
  }

  const data = await response.json()
  return {
    content: data.candidates[0].content.parts[0].text,
    reasoning: null,
  }
}

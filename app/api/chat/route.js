import { NextResponse } from "next/server"

// ØªÙƒÙˆÙŠÙ† timeout Ù„Ù„Ø·Ù„Ø¨Ø§Øª
const REQUEST_TIMEOUT = 45000 // 45 Ø«Ø§Ù†ÙŠØ©

// Ø¯Ø§Ù„Ø© Ù…Ø³Ø§Ø¹Ø¯Ø© Ù„Ø¥Ù†Ø´Ø§Ø¡ timeout
function createTimeout(ms) {
  return new Promise((_, reject) => {
    setTimeout(() => reject(new Error("Request timeout")), ms)
  })
}

// Ø¯Ø§Ù„Ø© Ù…Ø³Ø§Ø¹Ø¯Ø© Ù„Ø¥Ø±Ø³Ø§Ù„ Ø·Ù„Ø¨ Ù…Ø¹ timeout
async function fetchWithTimeout(url, options, timeoutMs = REQUEST_TIMEOUT) {
  const controller = new AbortController()
  const timeoutId = setTimeout(() => controller.abort(), timeoutMs)

  try {
    const response = await fetch(url, {
      ...options,
      signal: controller.signal,
    })
    clearTimeout(timeoutId)
    return response
  } catch (error) {
    clearTimeout(timeoutId)
    if (error.name === "AbortError") {
      throw new Error("Request timeout - Ø§Ù„Ø·Ù„Ø¨ Ø§Ø³ØªØºØ±Ù‚ ÙˆÙ‚ØªØ§Ù‹ Ø£Ø·ÙˆÙ„ Ù…Ù† Ø§Ù„Ù…ØªÙˆÙ‚Ø¹")
    }
    throw error
  }
}

export async function POST(request) {
  console.log("ğŸš€ Ø¨Ø¯Ø¡ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø·Ù„Ø¨ Ø§Ù„Ø¯Ø±Ø¯Ø´Ø©")

  try {
    // Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
    const body = await request.json()
    const { message, model, mode } = body

    console.log("ğŸ“ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø·Ù„Ø¨:", { message: message?.substring(0, 100), model, mode })

    if (!message || !message.trim()) {
      console.log("âŒ Ø±Ø³Ø§Ù„Ø© ÙØ§Ø±ØºØ©")
      return NextResponse.json({ error: "Ø§Ù„Ø±Ø³Ø§Ù„Ø© Ù…Ø·Ù„ÙˆØ¨Ø©" }, { status: 400 })
    }

    // Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙˆØ§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª
    let apiUrl, apiKey, modelName, headers

    switch (model) {
      case "deepseek":
        apiUrl = process.env.DEEPSEEK_API_URL || "https://api.deepseek.com/v1/chat/completions"
        apiKey = process.env.DEEPSEEK_API_KEY
        modelName = process.env.DEEPSEEK_AP_MODEL || "deepseek-chat"
        break

      case "groq":
        apiUrl = process.env.GROQ_API_URL || "https://api.groq.com/openai/v1/chat/completions"
        apiKey = process.env.GROQ_API_KEY
        modelName = process.env.GROQ_API_MODEL || "qwen/qwen3-32b"
        break

      case "together":
        apiUrl = process.env.TOGETHER_API_URL || "https://api.together.xyz/v1/chat/completions"
        apiKey = process.env.TOGETHER_API_KEY
        modelName = process.env.TOGETHER_API_MODEL || "deepseek-ai/DeepSeek-R1-Distill-Llama-70B-free"
        break

      case "gemini":
        apiUrl =
          process.env.GENERATE_CONTENT_API ||
          "https://generativelanguage.googleapis.com"
        apiKey = process.env.GEMINI_API_KEY
        modelName = process.env.MODEL_ID || "gemini-2.5-pro"
        break

      default:
        console.log("âŒ Ù†Ù…ÙˆØ°Ø¬ ØºÙŠØ± Ù…Ø¯Ø¹ÙˆÙ…:", model)
        return NextResponse.json({ error: "Ù†Ù…ÙˆØ°Ø¬ ØºÙŠØ± Ù…Ø¯Ø¹ÙˆÙ…" }, { status: 400 })
    }

    // Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ API Key
    if (!apiKey) {
      console.log("âŒ Ù…ÙØªØ§Ø­ API Ù…ÙÙ‚ÙˆØ¯ Ù„Ù„Ù†Ù…ÙˆØ°Ø¬:", model)
      return NextResponse.json({ error: `Ù…ÙØªØ§Ø­ API Ù…ÙÙ‚ÙˆØ¯ Ù„Ù„Ù†Ù…ÙˆØ°Ø¬ ${model}` }, { status: 500 })
    }

    console.log("ğŸ”‘ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬:", modelName)

    // Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø±Ø³Ø§Ø¦Ù„ Ø­Ø³Ø¨ Ø§Ù„ÙˆØ¶Ø¹
    let systemPrompt = "Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ø°ÙƒÙŠ Ù…ÙÙŠØ¯. Ø£Ø¬Ø¨ Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©."

    if (mode === "reasoning") {
      systemPrompt =
        "Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ø°ÙƒÙŠ Ù…ØªØ®ØµØµ ÙÙŠ Ø§Ù„ØªÙÙƒÙŠØ± Ø§Ù„Ø¹Ù…ÙŠÙ‚ ÙˆØ§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ù†Ø·Ù‚ÙŠ. ÙÙƒØ± Ø®Ø·ÙˆØ© Ø¨Ø®Ø·ÙˆØ© ÙˆÙ‚Ø¯Ù… ØªØ­Ù„ÙŠÙ„Ø§Ù‹ Ù…ÙØµÙ„Ø§Ù‹. Ø£Ø¬Ø¨ Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©."
    } else if (mode === "expert") {
      systemPrompt = "Ø£Ù†Øª Ø®Ø¨ÙŠØ± Ù…ØªØ®ØµØµ ÙÙŠ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ø¬Ø§Ù„Ø§Øª. Ù‚Ø¯Ù… Ø¥Ø¬Ø§Ø¨Ø§Øª Ù…ØªÙ‚Ø¯Ù…Ø© ÙˆÙ…ÙØµÙ„Ø© Ù…Ø¹ Ø£Ù…Ø«Ù„Ø© Ø¹Ù…Ù„ÙŠØ©. Ø£Ø¬Ø¨ Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©."
    } else if (mode === "planets") {
      systemPrompt =
        "Ø£Ù†Øª Ø®Ø¨ÙŠØ± ÙÙŠ Ø¹Ù„Ù… Ø§Ù„ÙÙ„Ùƒ ÙˆØ§Ù„ÙƒÙˆØ§ÙƒØ¨. Ù‚Ø¯Ù… Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¯Ù‚ÙŠÙ‚Ø© ÙˆÙ…ÙØµÙ„Ø© Ø¹Ù† Ø§Ù„ÙƒÙˆØ§ÙƒØ¨ ÙˆØ§Ù„Ù†Ø¬ÙˆÙ… ÙˆØ§Ù„ÙØ¶Ø§Ø¡. Ø£Ø¬Ø¨ Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©."
    }

    // Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø·Ù„Ø¨ Ø­Ø³Ø¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
    let requestBody, requestHeaders

    if (model === "gemini") {
      // ØªÙ†Ø³ÙŠÙ‚ Ø®Ø§Øµ Ø¨Ù€ Gemini
      requestBody = {
        contents: [
          {
            parts: [
              {
                text: `${systemPrompt}\n\nØ§Ù„Ø³Ø¤Ø§Ù„: ${message}`,
              },
            ],
          },
        ],
        generationConfig: {
          temperature: 0.7,
          maxOutputTokens: 4800,
        },
      }
      requestHeaders = {
        "Content-Type": "application/json",
        "x-goog-api-key": apiKey,
      }
      apiUrl = `${apiUrl}?key=${apiKey}`
    } else {
      // ØªÙ†Ø³ÙŠÙ‚ OpenAI Ø§Ù„Ù…Ø¹ÙŠØ§Ø±ÙŠ
      requestBody = {
        model: modelName,
        messages: [
          { role: "system", content: systemPrompt },
          { role: "user", content: message },
        ],
        temperature: 0.7,
        max_tokens: 4800,
      }
      requestHeaders = {
        "Content-Type": "application/json",
        Authorization: `Bearer ${apiKey}`,
      }
    }

    console.log("ğŸ“¤ Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ø·Ù„Ø¨ Ø¥Ù„Ù‰:", apiUrl.split("?")[0])

    // Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ø·Ù„Ø¨ Ù…Ø¹ timeout
    const response = await fetchWithTimeout(apiUrl, {
      method: "POST",
      headers: requestHeaders,
      body: JSON.stringify(requestBody),
    })

    console.log("ğŸ“¥ Ø­Ø§Ù„Ø© Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø©:", response.status)

    if (!response.ok) {
      const errorText = await response.text()
      console.error("âŒ Ø®Ø·Ø£ Ù…Ù† API:", errorText)

      let errorMessage = "Ø­Ø¯Ø« Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø®Ø§Ø¯Ù…"
      if (response.status === 401) {
        errorMessage = "Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ù…ØµØ§Ø¯Ù‚Ø© - ØªØ­Ù‚Ù‚ Ù…Ù† Ù…ÙØªØ§Ø­ API"
      } else if (response.status === 429) {
        errorMessage = "ØªÙ… ØªØ¬Ø§ÙˆØ² Ø§Ù„Ø­Ø¯ Ø§Ù„Ù…Ø³Ù…ÙˆØ­ - ÙŠØ±Ø¬Ù‰ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù„Ø§Ø­Ù‚Ø§Ù‹"
      } else if (response.status === 500) {
        errorMessage = "Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø®Ø§Ø¯Ù… - ÙŠØ±Ø¬Ù‰ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù„Ø§Ø­Ù‚Ø§Ù‹"
      }

      return NextResponse.json({ error: errorMessage }, { status: response.status })
    }

    const data = await response.json()
    console.log("âœ… ØªÙ… Ø§Ø³ØªÙ„Ø§Ù… Ø§Ù„Ø±Ø¯ Ø¨Ù†Ø¬Ø§Ø­")

    // Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ Ø­Ø³Ø¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
    let responseText = ""
    let reasoning = null

    if (model === "gemini") {
      responseText = data.candidates?.[0]?.content?.parts?.[0]?.text || "Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø±Ø¯"
    } else {
      responseText = data.choices?.[0]?.message?.content || "Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø±Ø¯"

      // Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ØªÙÙƒÙŠØ± Ø¥Ø°Ø§ ÙƒØ§Ù† Ù…ØªØ§Ø­Ø§Ù‹ (Ù„Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„ØªÙŠ ØªØ¯Ø¹Ù… Ø°Ù„Ùƒ)
      if (mode === "reasoning" && data.choices?.[0]?.message?.reasoning) {
        reasoning = data.choices[0].message.reasoning
      }
    }

    console.log("ğŸ“ Ø·ÙˆÙ„ Ø§Ù„Ø±Ø¯:", responseText.length)

    return NextResponse.json({
      response: responseText,
      reasoning: reasoning,
      mode: mode,
      model: model,
    })
  } catch (error) {
    console.error("ğŸ’¥ Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø·Ù„Ø¨:", error)

    let errorMessage = "Ø­Ø¯Ø« Ø®Ø·Ø£ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹"
    let statusCode = 500

    if (error.message.includes("timeout")) {
      errorMessage = "Ø§Ù†ØªÙ‡Øª Ù…Ù‡Ù„Ø© Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø© - ÙŠØ±Ø¬Ù‰ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù…Ø±Ø© Ø£Ø®Ø±Ù‰"
      statusCode = 408
    } else if (error.message.includes("fetch")) {
      errorMessage = "Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ø§Ù„Ø®Ø§Ø¯Ù…"
      statusCode = 503
    }

    return NextResponse.json({ error: errorMessage }, { status: statusCode })
  }
}

export async function GET() {
  return NextResponse.json({
    message: "Chat API is working",
    timestamp: new Date().toISOString(),
    models: ["deepseek", "groq", "together", "gemini"],
  })
}
